{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8df0bbd",
   "metadata": {},
   "source": [
    "# Identifying decision reasons (part 1)\n",
    "In this exercise, we will explore the capabilities of LLMs to identify decision reasons in verbal reports using the Hugging Face (HF) ecosystem. \n",
    "\n",
    "By the end of this exercise, you will have learned how to:\n",
    "- Design a zero-shot prompt\n",
    "- Have large models on the Hugging Face servers evaluate your prompts  \n",
    "- Validate the model output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979416b3c30fb86b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Using Notebook Environments \n",
    "1. To run a cell, press `shift + enter`. The notebook will execute the code in the cell and move to the next cell. If the cell contains a markdown cell (text only), it will render the markdown and move to the next cell.\n",
    "2. Since cells can be executed in any order and variables can be over-written, you may at some point feel that you have lost track of the state of your notebook. If this is the case, you can always restart the kernel by clicking Runtime in the menu bar (if you're using Colab) and selecting `Restart runtime`. This will clear all variables and outputs.\n",
    "3. The final variable in a cell will be printed on the screen. If you want to print multiple variables, use the `print()` function as usual.\n",
    "\n",
    "Notebook environments support code cells and markdown (text) cells. For the purposes of this workshop, markdown cells are used to provide high-level explanations of the code. More specific details are provided in the code cells themselves in the form of comments (lines beginning with `#`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c616368742ccde73",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:  # If in Google Colab environment\n",
    "    \n",
    "    # Installing requisite packages\n",
    "    !pip install huggingface_hub &> /dev/null\n",
    "\n",
    "    # Change working directory to day_1\n",
    "    %cd /content/drive/MyDrive/llms_egproc/exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c24c2ed829f80",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We begin by loading the requisite packages. For those coming from R, packages in Python are sometimes given shorter names for use in the code via the `import <name> as <nickname>` syntax (e.g. `import pandas as pd`). These are usually standardized nicknames. We here make use three packages:\n",
    "\n",
    "1. `pandas`: A very popular package for reading and manipulating data in python.\n",
    "2. `huggingface_hub`: A package for extracting features from text data using transformer-based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267fad62d6f82855",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc8d5804ede6511",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Choose your adventure\n",
    "\n",
    "- present three avenues (in text):\n",
    "- a) better model\n",
    "- b) improve prompt\n",
    "- c) other reasons\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4830e24a5d45430d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Adeventure A: Better model \n",
    "\n",
    "- change to llama 70b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81690eb2b6590715",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Adeventure B: improve prompt\n",
    "\n",
    "- or make it worse (e.g., remove chain of thoughts)\n",
    "- see how the model reacts to changes in the prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00f880-e9b0-44f5-9328-a4fc1e39a815",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Adventure C: other reasons \n",
    "\n",
    "- setup such that people can type in a reason\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
